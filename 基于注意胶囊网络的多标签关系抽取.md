# <center> 基于注意胶囊网络的多标签关系抽取 </center>

---
本文针对的任务是关系抽取任务，关系抽取任务。本篇论文[《Multi-labeled Relation Extraction with Attentive Capsule Network》](https://arxiv.org/abs/1811.04354)提出了基于注意力机制的胶囊网络模型，旨在解决一个句子中存在多种重叠关系的关系抽取任务，实现多标签分类。概括内容但是不吸引人。
___
- 之前的关系抽取的任务主要使用的是LSTM，或者CNN，attention机制和句法树等模型和方法来进行融合解决，但是对于两个实体之间有多种关系标签重叠的不能很好解决。
- 一组实体对，在句子中可能表达多种关系，而现在的神经网络模型最后的高维向量表示一般使用的max-pooling或者是句子级的attention，一个高维的关系向量并不能表示多种关系。
- 目前的方法会忽略离散的关系，而有些句子是由句中分散的词来形容实体之间的关系，目前常用的神经网络模型利用固定的结构，很难捕获不同位置上的关系特征。
- 目前在判断一个句子是否是“no relation”句子，仅仅当它不包含其它任何关系是，才会将其判断为“no relation”。

针对以上三个问题，本篇提出了基于注意力机制的胶囊网络，用于多标签的关系抽取任务，主要有三个创新点：将胶囊网络[hinton, Dynamic Routing Between Capsules](https://arxiv.org/abs/1710.09829)首次引进关系分类任务中；改进了hinton提出的胶囊网络中的动态路由算法提出基于注意力机制的动态路由；改进原来的损失函数提出滑动边界的损失函数用于更好地学习多种关系并判断“no relation”句子。

---

![注意胶囊网络模型图](http://ir.dlut.edu.cn/Uploads/ue/image/20190402/6368983583179926532379129.jpg)
如图所示的是本论文提出的方法整体架构图，模型的输入的是一句话和标注的两个实体，经过Bi-LSTM层，提取句子的低级特征表示，然后将相关特征通过注意力胶囊网络，聚类为一个高层次的关系表示，然后利用提出的滑动边界的算是函数进行分类和预测“no relation”句子。接下来分别详细地介绍特征提取层、特征聚类层和关系预测层。

#### 特征提取层
将词向量与位置向量拼接，经过Bi-LSTM获得前向特征和后向特征，然后将两个方向特征对应位置元素相加，获得最终的隐层表示：

![](http://ir.dlut.edu.cn/Uploads/ue/image/20190402/6368983583187726549121699.png)

#### 特征聚类层

![](http://ir.dlut.edu.cn/Uploads/ue/image/20190402/6368983583195526556864270.png)
![](http://ir.dlut.edu.cn/Uploads/ue/image/20190402/6368983584131528205972737.png)

h<sub>t</sub>为每个单词由特征提取层获得的隐层向量表示. g代表的是***squash***(浓缩果汁)激活函数。

在传统的动态路由算法中，对实体并不敏感，而在关系抽取过程中，实体也起到了重要的作用，因此在本篇论文中，改进传统的动态路由方法，增加了注意力机制，将关注点较多的放在了两个实体上，具体的算法如图4所示：
![](http://ir.dlut.edu.cn/Uploads/ue/image/20190402/6368983584156488242429694.jpg)

其中h<sub>e</sub>表示的是两个实体隐层特征加和，T表示的是转置计算，利用sigmoid函数计算得到实体与句中其余各词之间表示重要程度的权重值，然后再计算得到高级的特征表示r<sub>i</sub>：

![](http://ir.dlut.edu.cn/Uploads/ue/image/20190402/6368983585140849979222830.png)

其中w<sub>ij</sub>通过z迭代计算得到的系数，W<sub>j</sub>为权重，a<sub>i</sub>为attention权重值，g代表的是squash激活函数。

#### 特征预测层
本层将最终的胶囊模长表示关系的概率，这里作者对传统的胶囊网络的损失函数进行改进，提出了滑动边缘的损失函数，通过自动学习边界，对最终类进行预测，同时找到“no relation”的句子。损失函数如下公式所示：

![](http://ir.dlut.edu.cn/Uploads/ue/image/20190402/6368983585176730035179020.png)

其中B是变化参数，初始值设为0.5，在迭代过程中对其进行学习，γ为设置的边界超参数，当句子属于r<sub>j</sub>类时，Y<sub>j</sub>等于1，否则等于0。在解决“no relation”类型的关系时，所有的标记为“no relation”句子的概率都应该在边界以下。

---

本篇论文在两个数据集上进行实验，验证方法的有效性和泛化性。分别为：纽约时报数据（NYT-10）和SemEval-2010 Task 8评测数据，其中语料规模如表所示。：
<center>表一 数据集统计</center>
![](http://ir.dlut.edu.cn/Uploads/ue/image/20190402/6368983586129891717300046.jpg)

#### NYT-10数据集上的性能
在实验中，设定了6种特征聚类的方法作为对比方法，分别为：

- Max-pooling+CNN (Zeng et al. 2014).

- Max-pooling+RNN (Zhang and Wang 2015).

- Avg+RNN：经过RNN后的隐层特征加和取平均。

- Att+RNN (Zhou et al. 2016).

- Att-CapNet (CNN-based)

- Att-CapNet (RNN-based) 这个也是本实验中作者使用的方法。

表2所示的是在NYT-10数据集上，baseline方法的实验结果，PR表示的PR曲线面积。表3所示的是在NYT-10数据集上，baseline方法的PR曲线图。
<center>表二 NTY-10实验结果</center>
![](http://ir.dlut.edu.cn/Uploads/ue/image/20190402/6368983586137691725042616.jpg)

表3所示的是在NYT-10数据集上，进行十折交叉验证的实验结果，其中p-value值验证结果的有效性，p-value值越小实验结果越可信；CI表示经过十折交叉运算后，F1值的波动区间，其中F1值有不同程度的提高，最少也提高了2.2%。

<center>表三 NYT-10实验结果</center>
![](http://ir.dlut.edu.cn/Uploads/ue/image/20190402/6368983587171973549047838.jpg)

表4所示的是在SemEval-2010 Task 8数据集上，baseline方法的实验结果，其中WE表示词向量的维度，PE代表增加了位置特征。
<center>表4 SemEval-2010 Task 8实验结果</center>
![](http://ir.dlut.edu.cn/Uploads/ue/image/20190402/6368983587189133577762225.jpg)

<center>表6 SemEval-2010 Task 8不同模块性能评估</center>
![](http://ir.dlut.edu.cn/Uploads/ue/image/20190402/6368983587196933585504795.jpg)

为了验证提出的方法对于多标签分类是有效的，能够捕获实体对表达的不同类别信息，关注到句子中分散的实体关系，全面的分析句子中包含的关系类型， 选择了具有多标签的句子进行验证，实验结果举例如表7所示：
![](http://ir.dlut.edu.cn/Uploads/ue/image/20190402/6368983588207815367282306.jpg)

---

本篇论文中，作者对传统的胶囊网络进行改进，提出了基于注意力机制的动态路由来精确地提取关系特征；提出滑动边界的损失函数用于更好地学习多种关系并判断“no relation”句子。并且该论文是首篇将胶囊网络应用于多标签关系抽取任务上。目前在关系分类和实体识别任务上，应用胶囊网络方法的还不太多，且改进空间还很大；胶囊网络存在一个胶囊的长度就表示类别的概率值的性质，因此目前胶囊网络一般应用于最后一层，代替max-pooling层完成分类任务。作者在最后也提出，未来也可尝试解决阅读理解任何和其它的关系抽取任务。

本文虽然是关系抽取任务，但是着重点都在多标签关系分类上面，对于实体识别没有提及，由于没有开源代码，所以我也无法确定该实验在哪一步进行了实体识别。且文中对比的实验把引入句法信息和外部知识的那些方法排除在外，所以并不能说本文方法一定是最优的。且实验中并没有给出原始胶囊网络在该任务实验中的性能，因此也不能说本文对于胶囊网络的改进一定是有效的。

胶囊网络对于多标签的问题具有一定的契合度，在其他的多标签的问题上也可以尝试使用胶囊网络。